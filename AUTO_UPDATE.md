# 定期データ更新システム

このプロジェクトでは、GitHub Actionsを使用してWikipediaの「日本のナンバープレート一覧」ページから定期的にデータを取得し、既存のCSVファイルと突合して変更があった場合に自動的にプルリクエストを作成します。

## 🔄 自動更新システムの仕組み

### 実行スケジュール
- **定期実行**: 毎週月曜日の午前9時（JST）
- **手動実行**: GitHub Actionsのページから`workflow_dispatch`で手動実行可能

### 処理フロー

1. **データ取得**: Wikipediaの最新情報を取得
2. **データ比較**: 既存CSVファイルとの差分を検出
3. **自動PR作成**: 変更があった場合のみプルリクエストを作成

### 検出される変更

- ✅ **新しい登録地名の追加**
- ✅ **既存登録地名の削除**
- ✅ **運輸支局情報の変更**
- ✅ **読み仮名の修正**

## 📁 関連ファイル

```
.github/workflows/
└── update-plate-data.yml    # GitHub Actionsワークフロー

scripts/
└── fetch_wiki_data.py       # データ取得・比較スクリプト

number_plate_japan.csv       # メインデータファイル
```

## 🛠️ 手動実行方法

1. GitHubリポジトリのActionsタブに移動
2. 「Update Japanese License Plate Data」ワークフローを選択
3. 「Run workflow」ボタンをクリック
4. 実行結果を確認

## 📋 プルリクエストの内容

自動作成されるプルリクエストには以下の情報が含まれます：

- **変更概要**: 追加・削除・変更されたデータの詳細
- **取得日時**: データを取得した日時
- **ソースURL**: 参照したWikipediaページのURL
- **確認事項**: レビュー時のチェックポイント

## ⚙️ 技術詳細

### 依存ライブラリ
- `requests`: HTTP通信
- `beautifulsoup4`: HTML解析
- `pandas`: データ処理
- `lxml`: XML/HTML解析

### データ抽出ロジック
1. WikipediaのHTMLテーブルを解析
2. 地名、都道府県、運輸支局の情報を抽出
3. 読み仮名の自動生成（既知のマッピング + カタカナ→ひらがな変換）
4. 重複除去とデータクリーニング

### エラーハンドリング
- ネットワークエラー時の適切な処理
- データ形式が変更された場合の継続実行
- 無効なデータの除外

## 🔍 監視・メンテナンス

### ログ確認
GitHub Actionsのログでデータ取得状況を確認できます：
- 取得したレコード数
- 検出された変更内容
- エラーメッセージ（あれば）

### 定期メンテナンス
- Wikipediaの構造変更に対応するためのスクリプト調整
- 新しいご当地ナンバーの読み仮名追加
- エラー率の監視

## ⚠️ 注意事項

- Wikipediaの情報は随時更新されるため、公式な手続きには最新の官公庁資料をご確認ください
- 自動生成される読み仮名は参考情報として提供されます
- データの正確性は定期的に人手でも確認することを推奨します
